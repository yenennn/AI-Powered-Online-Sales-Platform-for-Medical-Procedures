import os
import time
import ast
import re
import numpy as np
import pandas as pd
from dotenv import load_dotenv
import docx
from langchain.text_splitter import RecursiveCharacterTextSplitter
from google import genai
from google.genai import types
from transitions import Machine

GREETING_PROMPT = """
Sen Dr.{doctor_name}'in {operation_name} operasyonu iÃ§in KARÅILAMA MODÃœLÃœSÃœNSÃœN.
AmaÃ§: Ä°lk olarak hastanÄ±n gerekli Ã¶n bilgilerini toplamalÄ± ve samimi bir ÅŸekilde selamlamalÄ±sÄ±n.

Talimatlar:
1. HastanÄ±n AdÄ± ve SoyadÄ±nÄ± sor.
2. HastanÄ±n YaÅŸÄ±nÄ± sor.
3. Herhangi bir Alerjisi olup olmadÄ±ÄŸÄ±nÄ± Ã¶ÄŸren ğŸ©º.
4. Operasyon iÃ§in beklenen tarih nedir? Sor ğŸ“†.
5. BulaÅŸÄ±cÄ± bir hastalÄ±ÄŸÄ± (Hepatitis B, Hepatitis C, HIV vb.) var mÄ±? Sor ğŸ˜·.
6. Herhangi bir saÄŸlÄ±k problemi veya dÃ¼zenli kullandÄ±ÄŸÄ± ilaÃ§ (HRT, tiroid, diyabet vb.) var mÄ±? Sor.
7. Boy ve kilo bilgisini al.
8. Daha Ã¶nce geÃ§irdiÄŸi ameliyatlar var mÄ±? Sor.

â€“ Her bir cevabÄ± aÃ§Ä±kÃ§a onayla, eksik bilgi kalÄ±rsa tekrar sor.
â€“ SorularÄ± arada boÅŸluk bÄ±rakmadan, akÄ±cÄ± ve empatik bir dille yÃ¶nelt.
â€“ TÃ¼m bilgiler toplandÄ±ktan sonra bu durumu kapat ve bir sonraki duruma geÃ§.
"""

INFO_REQUEST_PROMPT = """
Sen Dr.{doctor_name}'in {operation_name} operasyonu iÃ§in BÄ°LGÄ° MODÃœLÃœSÃœNSÃœN.
AmaÃ§: HastanÄ±n prosedÃ¼rle ilgili sorularÄ±na net, anlaÅŸÄ±lÄ±r ve empatik bir ÅŸekilde cevap vermelisin.

Talimatlar:
1. KullanÄ±cÄ±nÄ±n sorusunu Ã¶zetle ve en gÃ¼ncel tÄ±bbi bilgiyi ver.
2. Gerekirse RAGâ€™den Ã§ekilen pasajlardan kÄ±sa alÄ±ntÄ±lar ekle, ama â€œRAG kullandÄ±mâ€ deme.
3. EÄŸer ihtiyaÃ§ duyduÄŸunuzu dÃ¼ÅŸÃ¼nÃ¼yorsanÄ±z, ikna edici hikaye anlatÄ±mÄ± kullan: BaÅŸarÄ±lÄ± bir {operation.name} vakasÄ±nÄ±n anekdotunu paylaÅŸ. HastanÄ±n sana gÃ¼venmesini saÄŸla."
4. Teknik terimleri sadeleÅŸtir; hasta istemiyorsa karmaÅŸÄ±k jargon kullanma.
5. Her cevabÄ±nÄ±n sonunda hastaya baÅŸka bir isteÄŸi olup olmadÄ±ÄŸÄ±nÄ± farklÄ± ÅŸekillerde sor.
6. EÄŸer kullanÄ±cÄ± fiyatla ilgili bir soru sorarsa, bu oturumun durumunu 'negotiation' olarak gÃ¼ncelle.
"""

NEGOTIATION_PROMPT = """
Sen Dr.{doctor_name}'in {operation_name} operasyonu iÃ§in PAZARLIK MODÃœLÃœSÃœNSÃœN.
AmaÃ§: HastanÄ±n bÃ¼tÃ§esi ve baz fiyat Ã¼zerinden empatik bir pazarlÄ±k yÃ¼rÃ¼tmelisin.

Talimatlar:
1. Ã–nce doktorun baÅŸarÄ± oranÄ±nÄ± ve kalite gÃ¼vencesini vurgula:
   â€œDr. {doctor_name} %98 baÅŸarÄ± oranÄ±na sahipâ€¦â€ gibi.
2. KullanÄ±cÄ±dan bir fiyat teklifi gelmezse bÃ¼tÃ§e aralÄ±ÄŸÄ±nÄ± sor: â€œSizin iÃ§in makul bir fiyat aralÄ±ÄŸÄ± nedir? gibi bir soruylaâ€
3. Gelen teklife gÃ¶re fiyatÄ± ayarla:
   â€“ Pozitif duygu â†’ teklifi baz al + %5â€“10 artÄ±rÄ±m
   â€“ NÃ¶tr duygu   â†’ baz fiyatÄ± koru
   â€“ Negatif duyguâ†’ teklifi baz al â€“ %5â€“10 indirim
4. KullanÄ±cÄ±nÄ±n teklifi baz fiyatÄ±n %20 altÄ±ndaysa:
   â€œMaalesef bu aralÄ±k mÃ¼mkÃ¼n deÄŸil, lÃ¼tfen biraz yÃ¼kseltinâ€ de.
5. Her adÄ±mda aggregate_sentiment deÄŸerini kullanarak stratejini gÃ¼ncelle.
6. PazarlÄ±k tamamlandÄ±ÄŸÄ±nda durumu 'bye' olarak gÃ¼ncelle.
"""

TRANSITION_PROMPT = """
Sen Dr.{doctor_name}'in {operation_name} operasyonu iÃ§in DURUM GEÃ‡Ä°Å KONTROL MODÃœLÃœSÃœNSÃœN.
AmaÃ§: KullanÄ±cÄ±nÄ±n niyetine gÃ¶re durumlar arasÄ± geÃ§iÅŸ kurallarÄ±nÄ± uygula.

Talimatlar:
- Mevcut Durum: {current_state}
- KullanÄ±cÄ± MesajÄ±: {user_text}

OlasÄ± Durumlar: greeting, info_request, negotiation, bye
Kurallar:
 â€¢ KullanÄ±cÄ± â€œmerhabaâ€, â€œselamâ€ gibi ifadeler kullanÄ±rsa â†’ greeting
 â€¢ TÄ±bbi detay veya risk sorusu varsa â†’ info_request
 â€¢ Fiyat, Ã¶deme veya bÃ¼tÃ§e sorusu ise â†’ negotiation
 â€¢ Ã‡Ä±kÄ±ÅŸ yapmak istediÄŸini spesifik olarak belirtirse â†’ bye
 â€¢ HiÃ§biri eÅŸleÅŸmiyorsa â†’ mevcut durumda kal
EÄŸer operasyonla ilgili spesifik bir sorusu kalmadÄ±ÄŸÄ±ndan eminsen negotiation'a yÃ¶nlendir ve fiyat teklifi almaya Ã§alÄ±ÅŸ
YanÄ±t olarak yalnÄ±zca bir kelime ver: greeting, info_request, negotiation veya bye
"""
BYE_PROMPT = """
Sen Dr.{doctor_name}'in {operation_name} operasyonu iÃ§in VEDA MODÃœLÃœSÃœNSÃœN.
AmaÃ§: Sohbeti kibarca sonlandÄ±r.

Talimatlar:
â€“ â€œTeÅŸekkÃ¼rler, yardÄ±mcÄ± olabildiysem ne mutlu. GÃ¶rÃ¼ÅŸmek Ã¼zere.â€ gibi kibar bir veda et.
â€“ Tekrar gelmek isterlerse â€œHer zaman buradayÄ±mâ€ diye ekle.
"""


load_dotenv()

class LLMClient:
    def __init__(self, api_key=None, model="gemini-2.0-flash-lite"):
        self.api_key = api_key or os.getenv('GEMINI_KEY')
        self.client = genai.Client(api_key=self.api_key)
        self.model = model

    def analyze_sentiment(self, text):
        prompt = (
            "Sen Ã¶zel bir hasta-duygu sÄ±nÄ±flayÄ±cÄ±ysan. "
            "MesajÄ± oku ve yalnÄ±zca positive, neutral veya negative etiketlerinden biriyle yanÄ±t ver. "
            "Pozitif: hasta hevesli, heyecanlÄ± veya hazÄ±r olduÄŸunu ifade ediyorsa; "
            "NÃ¶tr: sadece bilgi amaÃ§lÄ± sorular soruyorsa; "
            "Negatif: Risklerden korktuÄŸunu belli ediyorsa, tereddÃ¼t veya Ã§ekingenlik gÃ¶steriyorsa. "
            f"Mesaj: \"{text}\""
        )
        response = self.client.models.generate_content(
            model=self.model,
            contents=prompt,
            config=types.GenerateContentConfig(max_output_tokens=10, temperature=0.0)
        )
        label = response.text.strip().lower()
        return label if label in ['positive','neutral','negative'] else 'neutral'

    def chat(self, messages, temperature=0.5, max_tokens=600):
        prompt = "\n".join(f"{m['role'].upper()}: {m['content']}" for m in messages)
        response = self.client.models.generate_content(
            model=self.model,
            contents=prompt,
            config=types.GenerateContentConfig(max_output_tokens=max_tokens, temperature=temperature)
        )
        return response.text.strip()

class Operation:
    def __init__(self, name, base_price):
        self.name = name
        self.base_price = base_price

class Doctor:
    def __init__(self, name, surname, specialty):
        self.name = name
        self.surname = surname
        self.specialty = specialty

STATES = ['greeting','info_request','negotiation','bye']

class ChatSession:
    STATE_PROMPTS = {
        'greeting': GREETING_PROMPT,
        'info_request': INFO_REQUEST_PROMPT,
        'negotiation': NEGOTIATION_PROMPT,
        'transition': TRANSITION_PROMPT,
        'bye': BYE_PROMPT
    }

    def __init__(self, operation, doctor, document_path, patient_risk=False):
        self.machine = Machine(model=self, states=STATES, initial='greeting')
        for s in STATES:
            self.machine.add_transition(trigger=f'to_{s}', source='*', dest=s)
        self.llm = LLMClient()
        self.operation = operation
        self.doctor = doctor
        self.document_path = document_path
        self.patient_risk = patient_risk
        self.model_embed = "gemini-embedding-exp-03-07"
        self.client_embed = genai.Client(api_key=self.llm.api_key)
        self.embeddings_df = self._generate_embeddings()
        modifier = 1.5 if patient_risk else 1.0
        self.base_price = operation.base_price * modifier
        self.last_offer = None
        self.base_temperature = 0.5
        self.visit_counts = {s: 0 for s in STATES}
        self.chat_history = []
        self.memory_summary = None
        self.state = 'greeting'
        self._add_message('system', self.STATE_PROMPTS['greeting'].format(
            doctor_name=self.doctor.name,
            operation_name=self.operation.name
        ))

    def _extract_text_and_tables_in_order(self):
        doc = docx.Document(self.document_path)
        full_text = []
        for element in doc.element.body:
            if element.tag.endswith('p'):
                para = docx.text.paragraph.Paragraph(element, doc)
                if para.text.strip():
                    full_text.append(para.text)
            elif element.tag.endswith('tbl'):
                table = docx.table.Table(element, doc)
                rows = []
                for row in table.rows:
                    cells = [cell.text.strip() for cell in row.cells]
                    rows.append("\t".join(cells))
                full_text.append("\n".join(rows))
        return "\n".join(full_text)

    def _split_text(self, text, chunk_size=1000, overlap=200):
        splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=overlap)
        return splitter.split_text(text)

    def _generate_embedding(self, text):
        response = self.client_embed.models.embed_content(model=self.model_embed, contents=text)
        time.sleep(10)
        return response.embeddings[0].values

    def _generate_embeddings(self):
        embeddings_file = "embeddings.csv"
        if os.path.exists(embeddings_file):
            df = pd.read_csv(embeddings_file)
            df['Embeddings'] = df['Embeddings'].apply(lambda x: np.array(ast.literal_eval(x), dtype=np.float64))
            return df
        text = self._extract_text_and_tables_in_order()
        chunks = self._split_text(text)
        df = pd.DataFrame({"chunk_id": list(range(1, len(chunks)+1)), "text": chunks})
        df['Embeddings'] = df['text'].apply(self._generate_embedding)
        df.to_csv(embeddings_file, index=False, encoding='utf-8')
        return df

    def find_best_passage(self, query):
        query_emb = self.client_embed.models.embed_content(model=self.model_embed, contents=query)
        query_vec = query_emb.embeddings[0].values
        corpus = np.stack(self.embeddings_df['Embeddings'].values)
        sims = corpus.dot(query_vec)
        best_idx = int(np.argmax(sims))
        idxs = [i for i in (best_idx-1, best_idx, best_idx+1) if 0 <= i < len(sims)]
        return " ".join(self.embeddings_df.iloc[idxs]['text'].values)

    def _add_message(self, role, content):
        sentiment = self.llm.analyze_sentiment(content)
        self.chat_history.append({'role': role, 'content': content, 'sentiment': sentiment, 'state': self.state})

    def _last_user_message(self):
        for msg in reversed(self.chat_history):
            if msg['role'] == 'user':
                return msg['content']
        return ''

    def _parse_next_state(self, response_text):
        candidate = response_text.strip().lower()
        return candidate if candidate in STATES else self.state

    def _build_prompt(self, user_text):
        transition = self.STATE_PROMPTS['transition'].format(
            doctor_name=self.doctor.name,
            operation_name=self.operation.name,
            current_state=self.state,
            user_text=user_text
        )
        trans_resp = self.llm.chat([
            {'role': 'system', 'content': transition},
            {'role': 'user', 'content': user_text}
        ], temperature=0.0, max_tokens=5)
        next_state = self._parse_next_state(trans_resp)
        if next_state != self.state:
            getattr(self, f'to_{next_state}')()
            self.state = next_state
        prompt = self.STATE_PROMPTS[self.state].format(
            doctor_name=self.doctor.name,
            operation_name=self.operation.name
        )
        return prompt

    def process_user(self, user_text):
        self._add_message('user', user_text)
        self.visit_counts[self.state] += 1
        temp = min(0.9, self.base_temperature + 0.1 * (self.visit_counts[self.state] - 1))
        ref = self.find_best_passage(user_text)
        prompt = self._build_prompt(user_text)
        if self.state == 'negotiation':
            sents = [m['sentiment'] for m in self.chat_history if m['role'] == 'user']
            agg = f"aggregate_sentiment: positive={sents.count('positive')}, neutral={sents.count('neutral')}, negative={sents.count('negative')}"
            system_content = f"{prompt}\n{agg}\nREFERENCE: {ref}"
        else:
            system_content = f"{prompt}\nREFERENCE: {ref}"
        msgs = [{'role': 'system', 'content': system_content}]
        if self.memory_summary:
            msgs.append({'role': 'system', 'content': f"memory_summary: {self.memory_summary}"})
        for m in self.chat_history:
            msgs.append({'role': m['role'], 'content': m['content']})
        reply = self.llm.chat(msgs, temperature=temp)
        self._add_message('assistant', reply)
        return reply


if __name__ == "__main__":
    load_dotenv()
    operation = Operation("Rhinoplasty", 5000)
    doctor = Doctor("Selcuk", "Coskun", "Plastic Surgeon")
    session = ChatSession(
        operation,
        doctor,
        "Definition and Purpose of Rhinoplasty.docx",
        patient_risk=False
    )
    while session.state != 'bye':
        user_input = input("You: ").strip()
        if not user_input:
            continue
        if user_input.lower() in ("exit", "quit"):
            print("Goodbye!")
            break
        print(session.process_user(user_input))
